{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from LeNet import LeNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NORMALIZE = False\n",
    "DEVICE = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "else:\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_home = '/data/winddy/'\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root=os.path.join(data_home, 'dataset/MNIST'), train=True, download=True, transform=trans)\n",
    "test_set = torchvision.datasets.MNIST(root=os.path.join(data_home, 'dataset/MNIST'), train=False, download=True, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 可视化数据集\n",
    "def imshow(img):\n",
    "    if NORMALIZE:\n",
    "        img = img * 0.3081 + 0.1307\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 5, 3, 0, 9, 6, 6, 2, 4, 7, 6, 0, 3, 8, 7, 5, 8, 0, 0, 2, 6, 2, 9, 1,\n",
      "        0, 6, 3, 3, 2, 5, 3, 8, 8, 9, 4, 0, 9, 9, 8, 0, 8, 1, 8, 4, 1, 6, 9, 3,\n",
      "        9, 2, 4, 3, 5, 6, 3, 5, 6, 7, 0, 4, 9, 2, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "# 可视化部分图片\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对抗训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if NORMALIZE:\n",
    "    model_path = './model/LeNet_MNIST.pt'\n",
    "else:\n",
    "    model_path = './model/LeNet_MNIST_unNormalize.pt'\n",
    "\n",
    "model = LeNet()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试正常数据的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10000|10000test loss: {0.0417}\n",
      "correct: {0.9858}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "target_arr = []\n",
    "output_arr = []\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        \n",
    "        test_loss += torch.nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        target_arr.append(target.cpu().data.numpy())\n",
    "        output_arr.append(output.cpu().data.numpy())\n",
    "        \n",
    "        count += len(data)\n",
    "        print('\\r {}|{}'.format(count, len(test_loader.dataset)), end='')\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "print('test loss: {%0.4f}' % test_loss)\n",
    "print('correct: {%0.4f}' % (correct/len(test_loader.dataset)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FGSM:\n",
    "    def __init__(self, model, criterion, epsilon, device):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        assert isinstance(model, torch.nn.Module), \"Input parameter model is not nn.Module. Check the model\"\n",
    "        assert isinstance(criterion, torch.nn.Module), \"Input parameter criterion is no Loss. Check the criterion\"\n",
    "        assert (0 <= epsilon <= 1), \"episilon must be 0 <= epsilon <= 1\"\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    def __call__(self, input, labels):\n",
    "        # For calculating gradient\n",
    "        input_for_gradient = Variable(input, requires_grad=True).to(self.device)\n",
    "        out = self.model(input_for_gradient)\n",
    "        loss = self.criterion(out, Variable(labels))\n",
    "\n",
    "        # Calculate gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate sign of gradient\n",
    "        signs = torch.sign(input_for_gradient.grad.data)\n",
    "\n",
    "        # Add\n",
    "        input_for_gradient.data = input_for_gradient.data + (self.epsilon * signs)\n",
    "\n",
    "        return input_for_gradient, signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fgsm = FGSM(model, criterion, epsilon, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成对抗样本并训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对抗攻击 对没有进行对抗训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: {10.7701}\n",
      "correct: {0.0326}\n"
     ]
    }
   ],
   "source": [
    "# 准备模型\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# 遍历数据集\n",
    "target_arr = []\n",
    "output_arr = []\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "    data, sign = fgsm(data, target)\n",
    "\n",
    "    output = model(data)\n",
    "    test_loss += torch.nn.functional.cross_entropy(output, target, reduction='sum').item()\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    target_arr.append(target.cpu().data.numpy())\n",
    "    output_arr.append(output.cpu().data.numpy())\n",
    "    \n",
    "    \n",
    "test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "print('test loss: {%0.4f}' % test_loss)\n",
    "print('correct: {%0.4f}' % (correct/len(test_loader.dataset)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_adv read the parameter of ./model/LeNet_MNIST_unNormalize.pt\n"
     ]
    }
   ],
   "source": [
    "model_adv = LeNet()\n",
    "model_adv.load_state_dict(torch.load(model_path))\n",
    "print('model_adv read the parameter of {}'.format(model_path))\n",
    "model_adv = model_adv.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model_adv.parameters(), lr=0.01, momentum=0.5)\n",
    "loss_F = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60000|60000test correct: 0.9409\n",
      "Epoch:0, loss0.008138871908870837\n",
      " 60000|60000test correct: 0.9741\n",
      "Epoch:1, loss0.001878611198440194\n",
      " 60000|60000test correct: 0.9716\n",
      "Epoch:2, loss0.0011520231779043873\n",
      " 60000|60000test correct: 0.9808\n",
      "Epoch:3, loss0.0008189000415926178\n",
      " 60000|60000test correct: 0.9843\n",
      "Epoch:4, loss0.0005971610893805822\n",
      " 60000|60000test correct: 0.985\n",
      "Epoch:5, loss0.000454725683790942\n",
      " 60000|60000test correct: 0.9846\n",
      "Epoch:6, loss0.00034746071957051755\n",
      " 60000|60000test correct: 0.9885\n",
      "Epoch:7, loss0.0002772072944790125\n",
      " 60000|60000test correct: 0.9831\n",
      "Epoch:8, loss0.00022108477900425593\n",
      " 60000|60000test correct: 0.9863\n",
      "Epoch:9, loss0.00016325688653935988\n"
     ]
    }
   ],
   "source": [
    "# 准备模型\n",
    "model.eval() # 产生对抗样本的模型\n",
    "model_adv.train() # 进行对抗训练的模型\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "\n",
    "# 遍历数据集\n",
    "\n",
    "for epoch in range(10):\n",
    "    tmp_loss = 0\n",
    "    count = 0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        data, sign = fgsm(data, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_adv(data)\n",
    "        loss = loss_F(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        tmp_loss += loss.item()\n",
    "        train_loss.append(loss.item())\n",
    "        count += len(data)\n",
    "        print('\\r {}|{}'.format(count, len(train_loader.dataset)), end='')\n",
    "      \n",
    "    # 测试\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "        data, sign = fgsm(data, target)\n",
    "\n",
    "        output = model_adv(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    print('test correct: {}'.format(correct/len(test_loader.dataset)))    \n",
    "    \n",
    "    print('Epoch:{}, loss{}'.format(epoch, tmp_loss/len(train_loader.dataset)))\n",
    "    \n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save successful model:./model/LeNet_MNIST_unNormalize_adv.pt\n"
     ]
    }
   ],
   "source": [
    "## 保存模型\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "if NORMALIZE:\n",
    "    model_path = './model/LeNet_MNIST_adv.pt'\n",
    "else:\n",
    "    model_path = './model/LeNet_MNIST_unNormalize_adv.pt'\n",
    "torch.save(model_adv.state_dict(), model_path)\n",
    "print('save successful model:{}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test correct: 0.5103\n"
     ]
    }
   ],
   "source": [
    "model_adv_new = LeNet()\n",
    "model_adv_new.load_state_dict(torch.load('./model/LeNet_MNIST_adv.pt'))\n",
    "model_adv_new = model_adv_new.to(DEVICE)\n",
    "\n",
    "model_adv_new.eval()\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "    data, sign = fgsm(data, target)\n",
    "\n",
    "    output = model_adv_new(data)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "print('test correct: {}'.format(correct/len(test_loader.dataset)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
